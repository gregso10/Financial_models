{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4eb6df",
   "metadata": {},
   "source": [
    "# Generate a real estate financial model using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeab290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/greg/code/gregso10/financial_models/real_estate/data/ValeursFoncieres-2025-S1.txt\", sep= \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76279d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3452216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37658032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e951e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"No voie\",\"Type de voie\",\"Voie\",\"Code postal\",\"Commune\",\"Valeur fonciere\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b08340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Commune\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = df[df[\"Commune\"] == \"PARIS 11\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38d66f",
   "metadata": {},
   "source": [
    "### Create a reduced DF which contains\n",
    "1. location\n",
    "2. price\n",
    "3. type\n",
    "4. size\n",
    "5. surface réelle batie\n",
    "6. surface terrain\n",
    "7. nature mutation\n",
    "\n",
    "Problèmes à résoudre: \n",
    "- identifier et rattacher les bonnes parcelles aux bonnes ventes\n",
    "--> certaines ventes sont sur plusieurs parcelles et composent plusieurs lots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Création d'un identifiant unique par transaction (Mutation)\n",
    "# Une mutation est définie par sa date, son numéro de disposition et sa valeur.\n",
    "reduced_df['id_mutation'] = (reduced_df['Date mutation'].astype(str) + '_' + \n",
    "                    reduced_df['Valeur fonciere'].astype(str) + '_' + \n",
    "                    reduced_df['No disposition'].astype(str) + '_' +\n",
    "                    reduced_df['Code commune'].astype(str))\n",
    "\n",
    "# 3. Filtrer uniquement les ventes (on exclut les échanges, adjudications, etc.)\n",
    "reduced_df = reduced_df[reduced_df['Nature mutation'] == 'Vente']\n",
    "\n",
    "# 4. Analyse des lots par transaction\n",
    "# On veut savoir combien de maisons et d'appartements il y a dans CHAQUE vente.\n",
    "def analyze_mutation(group):\n",
    "    # Compte des types de locaux\n",
    "    n_maisons = len(group[group['Type local'] == 'Maison'])\n",
    "    n_apparts = len(group[group['Type local'] == 'Appartement'])\n",
    "    n_dep = len(group[group['Type local'] == 'Dépendance'])\n",
    "    \n",
    "    # Surface totale habitable (uniquement maisons et apparts)\n",
    "    surface_reelle = group[group['Type local'].isin(['Maison', 'Appartement'])]['Surface reelle bati'].sum()\n",
    "    \n",
    "    # Récupération des infos uniques (Prix, Date, Adresse)\n",
    "    first_row = group.iloc[0]\n",
    "    \n",
    "    return pd.Series({\n",
    "        'valeur_fonciere': first_row['Valeur fonciere'],\n",
    "        'date': first_row['Date mutation'],\n",
    "        'commune': first_row['Commune'],\n",
    "        'n_maisons': n_maisons,\n",
    "        'n_apparts': n_apparts,\n",
    "        'n_dependances': n_dep,\n",
    "        'surface_habitable': surface_reelle,\n",
    "        'latitude': 48.85, # Simulé ici, à récupérer via géocodage\n",
    "        'longitude': 2.35  # Simulé ici\n",
    "    })\n",
    "\n",
    "# On regroupe par transaction\n",
    "df_transactions = reduced_df.groupby('id_mutation').apply(analyze_mutation).reset_index()\n",
    "\n",
    "# 5. Conversion du prix en numérique (le format français utilise la virgule)\n",
    "df_transactions['valeur_fonciere'] = df_transactions['valeur_fonciere'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FILTRAGE INTELLIGENT POUR LE MACHINE LEARNING\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# On garde uniquement les ventes \"unimates\" (1 seule unité d'habitation)\n",
    "# C'est-à-dire : (1 Maison et 0 Appart) OU (0 Maison et 1 Appart)\n",
    "df_ml = df_transactions[\n",
    "    ((df_transactions['n_maisons'] == 1) & (df_transactions['n_apparts'] == 0)) |\n",
    "    ((df_transactions['n_maisons'] == 0) & (df_transactions['n_apparts'] == 1))\n",
    "].copy()\n",
    "\n",
    "# 6. Calcul du Prix au m² (Variable cible clé)\n",
    "df_ml['prix_m2'] = df_ml['valeur_fonciere'] / df_ml['surface_habitable']\n",
    "\n",
    "# 7. Nettoyage final (retirer les surfaces nulles ou aberrantes)\n",
    "df_ml = df_ml[df_ml['surface_habitable'] > 9] # Exclure les \"micro-lots\" ou erreurs\n",
    "\n",
    "print(f\"Transactions brutes : {len(df_transactions)}\")\n",
    "print(f\"Transactions propres pour ML : {len(df_ml)}\")\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e596a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeck as pdk\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8caca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Fonction de Nettoyage ---\n",
    "def clean_dvf_data(df):\n",
    "    df['id_mutation'] = (df['Date mutation'].astype(str) + '_' + \n",
    "                         df['Valeur fonciere'].astype(str) + '_' + \n",
    "                         df['No disposition'].astype(str) + '_' + \n",
    "                         df['Code commune'].astype(str))\n",
    "\n",
    "    def analyze_mutation(group):\n",
    "        first = group.iloc[0]\n",
    "        # Construction adresse\n",
    "        num = str(int(first['No voie'])) if pd.notna(first['No voie']) else \"\"\n",
    "        type_voie = str(first['Type de voie']) if pd.notna(first['Type de voie']) else \"\"\n",
    "        voie = str(first['Voie']) if pd.notna(first['Voie']) else \"\"\n",
    "        code_postal = str(int(first['Code postal'])) if pd.notna(first['Code postal']) else \"\"\n",
    "        commune = str(first['Commune']) if pd.notna(first['Commune']) else \"\"\n",
    "        full_address = f\"{num} {type_voie} {voie} {code_postal} {commune}\".strip()\n",
    "        \n",
    "        return pd.Series({\n",
    "            'valeur_fonciere': float(str(first['Valeur fonciere']).replace(',', '.')),\n",
    "            'adresse_complete': full_address,\n",
    "            'surface_totale': group['Surface reelle bati'].sum()\n",
    "        })\n",
    "\n",
    "    # Filtrage Vente uniquement\n",
    "    return df[df['Nature mutation'] == 'Vente'].groupby('id_mutation').apply(analyze_mutation).reset_index()\n",
    "\n",
    "# --- 2. Chargement et Nettoyage ---\n",
    "try:\n",
    "    # Remplace par le chemin réel de ton fichier si nécessaire\n",
    "    df_raw = reduced_df \n",
    "    df_clean = clean_dvf_data(df_raw)\n",
    "    print(f\"Données nettoyées : {len(df_clean)} transactions uniques trouvées.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Erreur : Fichier introuvable. Vérifie le chemin.\")\n",
    "\n",
    "# --- 3. Géocodage (Avec barre de progression) ---\n",
    "print(\"Démarrage du géocodage...\")\n",
    "lats, lons = [], []\n",
    "\n",
    "for i, address in enumerate(df_clean['adresse_complete']):\n",
    "    if i % 5 == 0: # Affiche la progression tous les 5 items\n",
    "        print(f\"Traitement : {i}/{len(df_clean)}\", end=\"\\r\")\n",
    "        \n",
    "    if not address or len(address) < 5:\n",
    "        lats.append(None); lons.append(None)\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        url = \"https://api-adresse.data.gouv.fr/search/\"\n",
    "        response = requests.get(url, params={'q': address, 'limit': 1})\n",
    "        if response.json()['features']:\n",
    "            coords = response.json()['features'][0]['geometry']['coordinates']\n",
    "            lons.append(coords[0])\n",
    "            lats.append(coords[1])\n",
    "        else:\n",
    "            lats.append(None); lons.append(None)\n",
    "    except:\n",
    "        lats.append(None); lons.append(None)\n",
    "    time.sleep(0.05) # Respect de l'API\n",
    "\n",
    "df_clean['latitude'] = lats\n",
    "df_clean['longitude'] = lons\n",
    "df_geo = df_clean.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(f\"\\nGéocodage terminé : {len(df_geo)} adresses localisées.\")\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Fonction de Nettoyage ---\n",
    "def clean_dvf_data(df):\n",
    "    df['id_mutation'] = (df['Date mutation'].astype(str) + '_' + \n",
    "                         df['Valeur fonciere'].astype(str) + '_' + \n",
    "                         df['No disposition'].astype(str) + '_' + \n",
    "                         df['Code commune'].astype(str))\n",
    "\n",
    "    def analyze_mutation(group):\n",
    "        first = group.iloc[0]\n",
    "        # Construction adresse\n",
    "        num = str(int(first['No voie'])) if pd.notna(first['No voie']) else \"\"\n",
    "        type_voie = str(first['Type de voie']) if pd.notna(first['Type de voie']) else \"\"\n",
    "        voie = str(first['Voie']) if pd.notna(first['Voie']) else \"\"\n",
    "        code_postal = str(int(first['Code postal'])) if pd.notna(first['Code postal']) else \"\"\n",
    "        commune = str(first['Commune']) if pd.notna(first['Commune']) else \"\"\n",
    "        full_address = f\"{num} {type_voie} {voie} {code_postal} {commune}\".strip()\n",
    "        \n",
    "        return pd.Series({\n",
    "            'valeur_fonciere': float(str(first['Valeur fonciere']).replace(',', '.')),\n",
    "            'adresse_complete': full_address,\n",
    "            'surface_totale': group['Surface reelle bati'].sum()\n",
    "        })\n",
    "\n",
    "    # Filtrage Vente uniquement\n",
    "    return df[df['Nature mutation'] == 'Vente'].groupby('id_mutation').apply(analyze_mutation).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9780856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gps_coordinates(address):\n",
    "    \"\"\"\n",
    "    Interroge l'API Adresse (BAN) pour une adresse donnée.\n",
    "    Renvoie un tuple (latitude, longitude) ou (None, None) si échec.\n",
    "    \"\"\"\n",
    "    if not address or len(str(address)) < 5:\n",
    "        return None, None\n",
    "\n",
    "    API_URL = \"https://api-adresse.data.gouv.fr/search/\"\n",
    "    params = {\n",
    "        'q': address,\n",
    "        'limit': 1 # On veut juste le meilleur résultat\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(API_URL, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data['features']:\n",
    "                # L'API renvoie [long, lat], on veut (lat, long)\n",
    "                coords = data['features'][0]['geometry']['coordinates']\n",
    "                return coords[1], coords[0] \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur connexion pour {address}: {e}\")\n",
    "        \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11071111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Début du géocodage...\")\n",
    "\n",
    "# On crée deux listes vides\n",
    "lats = []\n",
    "lons = []\n",
    "\n",
    "# On boucle sur chaque ligne du DataFrame nettoyé\n",
    "for index, row in df_clean.iterrows():\n",
    "    lat, lon = get_gps_coordinates(row['adresse_complete'])\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    \n",
    "    # Petite pause pour être poli avec l'API (facultatif si peu de données)\n",
    "    # time.sleep(0.02) \n",
    "\n",
    "# On assigne les colonnes d'un coup\n",
    "df_clean['latitude'] = lats\n",
    "df_clean['longitude'] = lons\n",
    "\n",
    "# On retire les échecs (adresses introuvables)\n",
    "df_geo = df_clean.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(f\"Géocodage terminé ! {len(df_geo)} adresses localisées sur {len(df_clean)}.\")\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8600e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des couleurs (Logique de gradient simple)\n",
    "max_price = df_geo['valeur_fonciere'].max()\n",
    "df_geo['color'] = df_geo['valeur_fonciere'].apply(\n",
    "    lambda x: [int((x/max_price)*255), int(255-(x/max_price)*255), 50, 160]\n",
    ")\n",
    "\n",
    "# --- Configuration de la Carte ---\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=df_geo['latitude'].mean(),\n",
    "    longitude=df_geo['longitude'].mean(),\n",
    "    zoom=13,\n",
    "    pitch=50, # Inclinaison pour l'effet 3D\n",
    "    bearing=10\n",
    ")\n",
    "\n",
    "column_layer = pdk.Layer(\n",
    "    \"ColumnLayer\",\n",
    "    data=df_geo,\n",
    "    get_position=[\"longitude\", \"latitude\"],\n",
    "    get_elevation=\"valeur_fonciere\", # Hauteur = Prix\n",
    "    elevation_scale=0.05,            # Échelle à ajuster selon tes montants (0.01 à 0.1)\n",
    "    radius=30,                       # Largeur des colonnes en mètres\n",
    "    get_fill_color=\"color\",\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    "    extruded=True\n",
    ")\n",
    "\n",
    "# Tooltip (Info-bulle au survol)\n",
    "tooltip = {\n",
    "    \"html\": \"<b>Adresse:</b> {adresse_complete}<br/><b>Prix:</b> {valeur_fonciere} €\",\n",
    "    \"style\": {\"background\": \"grey\", \"color\": \"white\", \"font-family\": \"Arial\", \"z-index\": \"1000\"}\n",
    "}\n",
    "\n",
    "# --- Affichage ---\n",
    "r = pdk.Deck(\n",
    "    layers=[column_layer],\n",
    "    initial_view_state=view_state,\n",
    "    tooltip=tooltip,\n",
    "    map_style=\"mapbox://styles/mapbox/light-v9\"\n",
    ")\n",
    "\n",
    "# Cette commande affiche la carte DANS le notebook\n",
    "r.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86704ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8b5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GeoJsonLayer\n",
    "===========\n",
    "\n",
    "Property values in Vancouver, Canada, adapted from the deck.gl example pages. Input data is in a GeoJSON format.\n",
    "\"\"\"\n",
    "\n",
    "import pydeck as pdk\n",
    "\n",
    "DATA_URL = \"https://raw.githubusercontent.com/visgl/deck.gl-data/master/examples/geojson/vancouver-blocks.json\"\n",
    "LAND_COVER = [[[-123.0, 49.196], [-123.0, 49.324], [-123.306, 49.324], [-123.306, 49.196]]]\n",
    "\n",
    "INITIAL_VIEW_STATE = pdk.ViewState(latitude=49.254, longitude=-123.13, zoom=11, max_zoom=16, pitch=45, bearing=0)\n",
    "\n",
    "polygon = pdk.Layer(\n",
    "    \"PolygonLayer\",\n",
    "    LAND_COVER,\n",
    "    stroked=False,\n",
    "    # processes the data as a flat longitude-latitude pair\n",
    "    get_polygon=\"-\",\n",
    "    get_fill_color=[0, 0, 0, 20],\n",
    ")\n",
    "\n",
    "geojson = pdk.Layer(\n",
    "    \"GeoJsonLayer\",\n",
    "    DATA_URL,\n",
    "    opacity=0.8,\n",
    "    stroked=False,\n",
    "    filled=True,\n",
    "    extruded=True,\n",
    "    wireframe=True,\n",
    "    get_elevation=\"properties.valuePerSqm / 20\",\n",
    "    get_fill_color=\"[255, 255, properties.growth * 255]\",\n",
    "    get_line_color=[255, 255, 255],\n",
    ")\n",
    "\n",
    "r = pdk.Deck(layers=[polygon, geojson], initial_view_state=INITIAL_VIEW_STATE)\n",
    "\n",
    "r.to_html(\"geojson_layer.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ceb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real_estate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
